<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sliced on Modelling with R</title>
    <link>https://modelling-with-r.netlify.app/tags/sliced/</link>
    <description>Recent content in Sliced on Modelling with R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <lastBuildDate>Mon, 03 Oct 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://modelling-with-r.netlify.app/tags/sliced/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bayesian Sliced 3: Superstore profits</title>
      <link>https://modelling-with-r.netlify.app/bayes_superstore_profits/</link>
      <pubDate>Mon, 03 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/bayes_superstore_profits/</guid>
      <description>Summary:Background: In episode 3 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on superstore sales. The aim was to predict the profit on each sale in the test set.
My approach: I start with the model used in my non-Bayesian analysis of these data, which transformed the profit to the profit that would have been obtained had there not been a discount.</description>
    </item>
    
    <item>
      <title>Bayesian Sliced 2: Wildlife Strikes</title>
      <link>https://modelling-with-r.netlify.app/bayes_wildlife_strikes/</link>
      <pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/bayes_wildlife_strikes/</guid>
      <description>Summary:Background: In episode 2 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on wildlife strikes with aircraft. The aim was to predict whether or not the aircraft was damaged in the collision.
My approach: The database was created by the FAA from reports filed by pilots that are clearly incomplete. For my previous post, I spent the vast majority of the time cleaning the data and afterwards used a logistic regression model.</description>
    </item>
    
    <item>
      <title>Bayesian Sliced 1: Boardgame Ratings</title>
      <link>https://modelling-with-r.netlify.app/bayes_boardgames/</link>
      <pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/bayes_boardgames/</guid>
      <description>SummaryBackground: In episode 1 of the 2021 series of Sliced, the competitors were given two hours to analyse a set of data on boardgames. The aim was to predict the games’ ratings.
My approach: In an earlier post entitled Sliced Episode 1: Boardgame Ratings, I analysed these data using traditional methods. That post describes my data cleaning, feature selection and data exploration. In this analysis, I take those same cleaned data and analyse them using a Bayesian model.</description>
    </item>
    
    <item>
      <title>Sliced Episode 12: Loan Defaults</title>
      <link>https://modelling-with-r.netlify.app/loan_defaults/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/loan_defaults/</guid>
      <description>SummaryBackground: In the final (episode 12) of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on bank loans. The aim was to predict the size of the default on the loan (usually zero). The metric for evaluation was the mean absolute error.
My approach: I explored the data and decided to build two models, one to predict whether or not the customer would default and the other to predict the size of the default in customers who defaulted.</description>
    </item>
    
    <item>
      <title>Sliced Episode 11: Austin House Prices</title>
      <link>https://modelling-with-r.netlify.app/zillow/</link>
      <pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/zillow/</guid>
      <description>Summary:Background: In episode 11 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on properties in the Austin area that were advertised on Zillow. The aim was to predict the house price, lumped into 5 categories.
My approach: I decided to use these data to illustrate the use of pipelines in mlr3. I identify commonly used words from the estate agents description of the property and use a pipeline to filter them and combine the selected keywords with the numerical descriptors of the property.</description>
    </item>
    
    <item>
      <title>Sliced Episode 10: Animal adoption</title>
      <link>https://modelling-with-r.netlify.app/animal_adoption/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/animal_adoption/</guid>
      <description>IntroductionThe data for episode 10 of Sliced, the second round of the play-offs, relates to the adoption of abandoned or unwanted pets. Given information about the animal, such as its breed and age, the competitors had to predict a three class outcome, either, adoption, transfer or what is euphemistically called ‘no outcome’, which in reality means that the animal was put down (another euphemism).
The data can be downloaded from https://www.</description>
    </item>
    
    <item>
      <title>Methods: Introduction to mlr3</title>
      <link>https://modelling-with-r.netlify.app/mlr3/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/mlr3/</guid>
      <description>IntroductionThis post introduces the ecosystem of packages known as mlr3. It is an alternative to tidymodels and one of my reasons for trying mlr3 was to compare the two.
mlr3 is built on R6. a package that enables Object Oriented Programming (OOP) in R. To understand the way that mlr3 works, it is helpful to know a little about OOP and R6, so that is where I will start.</description>
    </item>
    
    <item>
      <title>Sliced Episode 9: Baseball home runs</title>
      <link>https://modelling-with-r.netlify.app/baseball/</link>
      <pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/baseball/</guid>
      <description>SummaryBackground: In episode 9 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on baseball. The aim was to predict whether or not a hit went for a home run.
My approach: I ran an extensive exploratory analysis relating the percentage of home runs to each of the exploratory factors. The type of hit is extremely predictive; for instance, you cannot hit a home run off a ground ball.</description>
    </item>
    
    <item>
      <title>Sliced Episode 8: Spotify Popularity</title>
      <link>https://modelling-with-r.netlify.app/spotify/</link>
      <pubDate>Mon, 18 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/spotify/</guid>
      <description>SummaryBackground: In episode 8 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on tracks available on Spotify. The aim was to predict the track popularity.
My approach: I merged the data on the tracks with data on the artists and then identified genres that were associated with the track popularity. Using all available information, I fitted a random forest model using default values of the hyperparameters.</description>
    </item>
    
    <item>
      <title>Sliced Episode 7: Customer Churn</title>
      <link>https://modelling-with-r.netlify.app/customer_churn/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/customer_churn/</guid>
      <description>Summary:Background: In episode 7 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on bank customers. The aim was to predict whether a customer would churn (leave the bank).
My approach: I started with the idea that people churn for different reasons and because of this, it will be difficult to find a single scale that distinguishes churners from non-churners.</description>
    </item>
    
    <item>
      <title>Sliced Episode 6: Ranking Games on Twitch</title>
      <link>https://modelling-with-r.netlify.app/rank_games/</link>
      <pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/rank_games/</guid>
      <description>SummaryBackground: In episode 6 of the 2021 series of Sliced, the competitors were given two hours to analyse a set of data on the top 200 games broadcast on twitch. The aim was to predict their exact rankings.
My approach: The ranking is based on the number of hours of streaming that were watched. Presumably the organisers did not notice that they provided two predictors, which when multiplied gave the number of hours watched.</description>
    </item>
    
    <item>
      <title>Sliced Episode 5: Airbnb Price Prediction</title>
      <link>https://modelling-with-r.netlify.app/airbnb_prices/</link>
      <pubDate>Mon, 20 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/airbnb_prices/</guid>
      <description>Summary:Background: In episode 5 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on Airbnb properties in New York City. The aim was to predict the price per night.
My approach: I work on a log(price + 1) scale as suggested by the evaluation metric. I spend quite a lot of time on feature extraction. I extract keywords from the description of the property and I merge geographically close neighbourhoods with few properties.</description>
    </item>
    
    <item>
      <title>Sliced Episode 4: Rain Tomorrow</title>
      <link>https://modelling-with-r.netlify.app/rain_tomorrow/</link>
      <pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/rain_tomorrow/</guid>
      <description>Summary:Background: In episode 4 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on daily weather patterns in different parts of Australia. The aim was to predict whether or not it will rain the next day.
My approach: I started with the idea that location would be key to a good model and I tried two approaches, one based on average rainfall patterns for the time of year and the other based on a day’s weather predicting the weather on the following day.</description>
    </item>
    
    <item>
      <title>Sliced Episode 3: Superstore profits</title>
      <link>https://modelling-with-r.netlify.app/superstore_profits/</link>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/superstore_profits/</guid>
      <description>Summary:Background: In episode 3 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on superstore sales. The aim was to predict the profit on a sale.
My approach: This is a good example of a problem for which we have knowledge about the structure of the data. In particular, we know the relation between sales, cost, discount and profit.</description>
    </item>
    
    <item>
      <title>Sliced Episode 2: Wildlife Strikes</title>
      <link>https://modelling-with-r.netlify.app/wildlife_strikes/</link>
      <pubDate>Sun, 12 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/wildlife_strikes/</guid>
      <description>Summary:Background: In episode 2 of the 2021 series of Sliced, the competitors were given two hours in which to analyse a set of data on wildlife strikes with aircraft. The aim was to predict whether or not the aircraft was damaged in the collision.
My approach: The original database was created by the FAA from reports filed by pilots and reporting is clearly incomplete. I spent the vast majority of my time cleaning the data and afterwards used a logistic regression model.</description>
    </item>
    
    <item>
      <title>Sliced Episode 1: Boardgame Ratings</title>
      <link>https://modelling-with-r.netlify.app/boardgames/</link>
      <pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/boardgames/</guid>
      <description>SummaryBackground: In episode 1 of the 2021 series of Sliced, the competitors were given two hours to analyse a set of data on boardgames. The aim was to predict the games’ ratings.
My approach: In the data exploration I transform the ratings and plot them against the potential predictors. I note inconsistencies in the data. The mechanics of the game and the type of game are described as text, so I create indicator variables for the words most closely associated with the games’ ratings.</description>
    </item>
    
    <item>
      <title>Sliced Methods Overview</title>
      <link>https://modelling-with-r.netlify.app/methods_overview/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/methods_overview/</guid>
      <description>IntroductionWhen analysing the Sliced datasets I have tried to use a consistent approach in order that my code is easier to follow. In this post I will give an overview of my approach.
Naming of partsThe first thing that you will notice about my code is that all tibbles and data frames are given names that end in DF. Sorry if you don’t like it, but I find it helpful to distinguish the data frame names for the names of variables that sit within the data frame.</description>
    </item>
    
    <item>
      <title>Sliced 2021 Episode Overview</title>
      <link>https://modelling-with-r.netlify.app/sliced-2021-overview/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://modelling-with-r.netlify.app/sliced-2021-overview/</guid>
      <description>IntroductionSliced is a data science competition hosted by Nick Wan and Meg Risdal on twitch ( https://www.twitch.tv/nickwan_datasci ). In each episode, 4 data scientists with very different backgrounds are given the same dataset and in 2 hours they must explore the data and build a predictive model. As well as the training data, they are given a test set that lacks the variable to be predicted. The model that best predicts in the test data according to a specified metric, wins the prediction element of the competition, but other points are available for data visualization, golden features and popularity as voted for by chat.</description>
    </item>
    
  </channel>
</rss>
